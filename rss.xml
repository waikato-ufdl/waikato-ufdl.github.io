<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>User-friendly Deep Learning</title><link>https://waikato-ufdl.github.io/</link><description>Making deep learning accessible to domain experts without having to rely on machine learning experts</description><atom:link href="https://waikato-ufdl.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019-2020 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Tue, 25 Aug 2020 02:49:04 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Keras image segmentation Docker image available</title><link>https://waikato-ufdl.github.io/news/2020-08-25-keras-image-segmentation-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;A new Docker image is available for training &lt;em&gt;Keras image segmentation&lt;/em&gt; models using a GPU backend.
The image is based on TensorFlow 1.14 and Divam Gupta's &lt;a class="reference external" href="https://github.com/divamgupta/image-segmentation-keras"&gt;code&lt;/a&gt;,
plus additional tools for converting indexed PNGs into RGB ones and continuously processing images with a model.&lt;/p&gt;
&lt;p&gt;More information on the Docker image is available from Github:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras"&gt;github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-08-25-keras-image-segmentation-docker/</guid><pubDate>Tue, 25 Aug 2020 02:35:00 GMT</pubDate></item><item><title>New Pytoch Docker images available</title><link>https://waikato-ufdl.github.io/news/2020-08-14-pytorch-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;A couple of Docker images using &lt;a class="reference external" href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; are now available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/crnn-audio-classification"&gt;Audio classification using CRNNs&lt;/a&gt;
(code by &lt;a class="reference external" href="https://github.com/ksanjeevan/crnn-audio-classification"&gt;Kiran Sanjeevan&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/deepspeech2"&gt;DeepSpeech2&lt;/a&gt;
(code by &lt;a class="reference external" href="https://github.com/SeanNaren/deepspeech.pytorch"&gt;Sean Naren&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-08-14-pytorch-docker/</guid><pubDate>Thu, 13 Aug 2020 23:50:00 GMT</pubDate></item><item><title>wai.lazypip release</title><link>https://waikato-ufdl.github.io/news/2020-07-29-wailazypip-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;An initial release of &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-lazypip"&gt;wai.lazypip&lt;/a&gt;
is out now: &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-lazypip/releases/tag/v0.0.1"&gt;0.0.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;wai.lazypip&lt;/em&gt; is a little helper library that can install additional packages within
a virtual environment on demand if required modules, functions, attributes or classes
are not present. Under the hood, &lt;em&gt;pip&lt;/em&gt; is used for installing the additional packages.&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-07-29-wailazypip-release/</guid><pubDate>Tue, 28 Jul 2020 22:40:00 GMT</pubDate></item><item><title>ADAMS snapshots now publicly available</title><link>https://waikato-ufdl.github.io/news/2020-07-24-adams-snapshots/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;The newly available &lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-frontend-adams"&gt;ufdl-frontend-adams&lt;/a&gt; modules for
&lt;a class="reference external" href="https://adams.cms.waikato.ac.nz/"&gt;ADAMS&lt;/a&gt; now have public builds available for download:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://adams.cms.waikato.ac.nz/snapshots/ufdl/"&gt;adams.cms.waikato.ac.nz/snapshots/ufdl/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As of now, the following workflows can be used for managing a UFDL server instance and datasets:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;adams-ufdl-core-manage_backend.flow&lt;/em&gt; - manages users, teams, projects, licenses&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;adams-ufdl-image-manage_image_classification_datasets.flow&lt;/em&gt; - for image classifications datasets&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;adams-ufdl-image-manage_object_detection_datasets.flow&lt;/em&gt; - for object detection datasets&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;adams-ufdl-speech-manage_speech_datasets.flow&lt;/em&gt; - for speech datasets&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; In order to utilize these flows, you need to have an instance of the
&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-backend"&gt;ufdl-backend&lt;/a&gt; running, of course.&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-07-24-adams-snapshots/</guid><pubDate>Thu, 23 Jul 2020 21:41:00 GMT</pubDate></item><item><title>Github repositories now publicly availably</title><link>https://waikato-ufdl.github.io/news/2020-07-22-repos-public/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;The (very much work-in-progress) code of the following UFDL repositories is now
publicly available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-backend"&gt;ufdl-backend&lt;/a&gt; - the Djano REST API backend&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-json-messages"&gt;ufdl-json-messages&lt;/a&gt; - the JSON messages used by backend and Python client&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-python-client"&gt;ufdl-python-client&lt;/a&gt; - the core Python client encapsulating the REST API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-java-client"&gt;ufdl-java-client&lt;/a&gt; - the core Java client encapsulating the REST API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-ufdl/ufdl-frontend-adams"&gt;ufdl-frontend-adams&lt;/a&gt; - &lt;a class="reference external" href="https://adams.cms.waikato.ac.nz/"&gt;ADAMS&lt;/a&gt; modules that make use of the Java client, providing access to the REST API within the workflow environment (include flows for managing backend and datasets)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-07-22-repos-public/</guid><pubDate>Tue, 21 Jul 2020 21:26:00 GMT</pubDate></item><item><title>DeepSpeech Docker image available</title><link>https://waikato-ufdl.github.io/news/2020-07-03-deepspeech-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;A new Docker image is available for training &lt;a class="reference external" href="https://github.com/mozilla/DeepSpeech"&gt;DeepSpeech&lt;/a&gt; models using a GPU backend.
The image is based on Mozilla's DeepSpeech 0.7.4 one for training models, adding more functionality to it:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;support for MP3 and OGG files, not just WAV&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;automatic alphabet generation from the transcripts&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;split sound files into chunks based on detected pauses&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;batch process audio files (can be continuous)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;many Python utilities have been sym-linked&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More information on the Docker image is available from Github:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/deepspeech"&gt;github.com/waikato-datamining/tensorflow/tree/master/deepspeech&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-07-03-deepspeech-docker/</guid><pubDate>Fri, 03 Jul 2020 04:26:00 GMT</pubDate></item><item><title>wai.annotations release 0.4.0</title><link>https://waikato-ufdl.github.io/news/2020-07-02-waiannotations-release-0-4-0/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;A new release of &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations"&gt;wai.annotations&lt;/a&gt; is out now: &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations/releases/tag/v0.4.0"&gt;0.4.0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This release represents a major refactoring, introducing domains other than object-detection in images.
Another notable change is being able to add filters into the conversion pipeline. This will, e.g., allow the
augmentation of datasets while converting them. In terms of object detection datasets, these augmentations can be
rotation, cropping, brightening/darkening, etc. Though a lot of frameworks already support basic augmentation
transformations, trying to automatically augment bounding boxes rather than object shapes can lead to strange
and undesirable artifacts (e.g., overly large boxes, overlapping annotations).&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-07-02-waiannotations-release-0-4-0/</guid><pubDate>Wed, 01 Jul 2020 23:57:00 GMT</pubDate></item><item><title>MMDetection Docker image using CUDA 10</title><link>https://waikato-ufdl.github.io/news/2020-06-17-mmdetection-docker-cuda10/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;The previously release Docker images for MMDetection only worked with PyTorch 1.3 on CUDA 10.1, which only worked on NVIDIA 2080 Ti cards, but not 1080 Ti ones. Today, we released a new Docker image which is based on PyTorch 1.2 and CUDA 10.0, which allows 1080 Ti cards to be used again:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmdetection/tree/master/2020-03-01_cuda10"&gt;github.com/waikato-datamining/mmdetection/tree/master/2020-03-01_cuda10&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-06-17-mmdetection-docker-cuda10/</guid><pubDate>Tue, 16 Jun 2020 22:09:00 GMT</pubDate></item><item><title>MMDetection Docker image available</title><link>https://waikato-ufdl.github.io/news/2020-06-02-mmdetection-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;New Docker images are available for the &lt;a class="reference external" href="https://github.com/open-mmlab/mmdetection"&gt;MMDetection&lt;/a&gt; object detection framework, using the 1.2.0 (code base as of 2020-03-01) release of MMDetection:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmdetection/tree/master/2020-03-01"&gt;github.com/waikato-datamining/mmdetection/tree/master/2020-03-01&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-06-02-mmdetection-docker/</guid><pubDate>Tue, 02 Jun 2020 04:21:00 GMT</pubDate></item><item><title>YOLACT/YOLACT++ Docker images available</title><link>https://waikato-ufdl.github.io/news/2020-04-03-yolact-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;div&gt;&lt;p&gt;The first Docker images are available for the &lt;a class="reference external" href="https://github.com/dbolya/yolact/"&gt;YOLACT&lt;/a&gt; (You Only Look At CoefficienTs) image segmentation model, using the 1.2 release:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/yolact"&gt;github.com/waikato-datamining/yolact&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;YOLACT/YOLACT++, like MMDetection, is based on &lt;a class="reference external" href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt;. In contrast to MMDetection it is not a divers framework, but just a single model, which can make use of various base models (e.g., ResNet50). Similar to Mask R-CNN, it generates a mask with probabilities for each identified object, which requires post-processing to determine a &lt;a class="reference external" href="https://scikit-image.org/docs/0.17.x/auto_examples/edges/plot_contours.html"&gt;polygon&lt;/a&gt; or &lt;a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=minarearect#minarearect"&gt;minimal rectangle&lt;/a&gt;. However, it is much faster than the Mask R-CNN implementation that TensorFlow's Object Detection API offers (roughly 3x faster on 1000x300 images).&lt;/p&gt;&lt;/div&gt;</description><category>release</category><guid>https://waikato-ufdl.github.io/news/2020-04-03-yolact-docker/</guid><pubDate>Thu, 02 Apr 2020 22:38:00 GMT</pubDate></item></channel></rss>